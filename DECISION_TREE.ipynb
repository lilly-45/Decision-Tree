{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Decision tree\n",
        "\n",
        "\n",
        "1.  What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "  \n",
        "      -> A Decision Tree is a supervised machine learning algorithm used for classification and also regression. It works like a flowchart, where decisions are made step by step by splitting the dataset into smaller subsets based on feature values.\n",
        "\n",
        "   i. Root Node Selection\n",
        "\n",
        "The tree starts with all the data at the root.\n",
        "An algorithm chooses the best feature to split the data into classes.\n",
        "“Best” is decided using measures like:\n",
        "Gini Index\n",
        "Entropy / Information Gain\n",
        "Chi-square\n",
        "\n",
        "   ii. Splitting\n",
        "\n",
        "The dataset is divided into subsets based on the chosen feature’s values.\n",
        "Example: If the feature is “Weather” → branches could be “Sunny,” “Rainy,” “Cloudy.”\n",
        "\n",
        "   iii. Recursive Partitioning\n",
        "\n",
        "For each subset, the process is repeated:\n",
        "choose the best feature → split further → create new nodes.\n",
        "\n",
        "   iv. Stopping Criteria\n",
        "  Splitting continues until:\n",
        "\n",
        "  All samples in a node belong to the same class, or\n",
        "\n",
        "  No further improvement can be made, or\n",
        "The tree reaches a maximum depth or minimum samples per node.\n",
        "\n",
        "   v. Prediction\n",
        "\n",
        "To classify a new observation, it is passed through the tree:\n",
        "\n",
        "Start at root → follow branches according to feature values → reach a leaf node → predict the class.\n",
        "\n",
        "\n",
        "2. Explain the concepts of Gini Impurity and Entropy as impurity measures.\n",
        "How do they impact the splits in a Decision Tree?\n",
        "\n",
        "   -> Gini Impurity\n",
        "\n",
        " Probability of incorrectly classifying a randomly chosen element if it was labeled according to the distribution of classes in the node.\n",
        "\n",
        "   Entropy (Information Gain)\n",
        "\n",
        "  Measures the disorder (uncertainty) in a dataset.\n",
        "  Comes from information theory.\n",
        "\n",
        "When building a decision tree, the algorithm must decide which feature to split on at each step.\n",
        "\n",
        "A “good” split is one that creates pure subsets (nodes where most samples belong to a single class).\n",
        "\n",
        "To measure this purity/impurity, metrics like Gini Impurity and Entropy are used.\n",
        "\n",
        "When building the tree:\n",
        "\n",
        "For each candidate feature → compute Gini/Entropy for the subsets after the split.\n",
        "\n",
        "Choose the split that reduces impurity the most.\n",
        "This ensures splits make nodes purer, moving toward classification certainty.\n",
        "\n",
        "\n",
        "3. What is the difference between Pre-Pruning and Post-Pruning in Decision\n",
        "Trees? Give one practical advantage of using each.\n",
        "\n",
        "   -> Pruning in Decision Trees\n",
        "\n",
        "Decision trees tend to grow deep and complex, perfectly fitting training data but generalizing poorly (overfitting).\n",
        "\n",
        "Pruning reduces tree complexity by stopping splits or removing unnecessary branches.\n",
        "\n",
        "There are two types: Pre-pruning and Post-pruning.\n",
        "\n",
        "   i.Pre-Pruning (Early Stopping)\n",
        "\n",
        "Stop the tree from growing too deep during training.\n",
        "\n",
        "Use conditions like:\n",
        "\n",
        "   Maximum depth of the tree (max_depth)\n",
        "\n",
        "   Minimum samples required to split (min_samples_split)\n",
        "\n",
        "   Minimum samples at a leaf (min_samples_leaf)\n",
        "\n",
        "   Minimum impurity decrease\n",
        "\n",
        "   Practical Advantage:\n",
        "   Faster training & smaller trees → useful in real-time applications where speed and memory efficiency matter (e.g., quick classification in mobile apps).\n",
        "\n",
        "   ii. Post-Pruning (Cost-Complexity Pruning / Reduced Error Pruning)\n",
        "\n",
        "   First, grow the full tree (possibly overfitted).\n",
        "\n",
        "   Then prune back branches that do not improve accuracy on a validation set.\n",
        "\n",
        "  Approaches:\n",
        "\n",
        "   Reduced Error Pruning: Remove a branch if accuracy does not drop.\n",
        "\n",
        "  Cost-Complexity Pruning (CCP): Balance accuracy vs tree size.\n",
        "\n",
        "Practical Advantage:\n",
        "   Better generalization → since the tree first explores all splits, pruning ensures only meaningful branches remain (e.g., credit scoring models where interpretability + accuracy is important).\n",
        "\n",
        "\n",
        "4. What is Information Gain in Decision Trees, and why is it important for\n",
        "choosing the best split?\n",
        "\n",
        "   -> Information Gain (IG) is a metric used to decide which feature to split on at each step in a decision tree.\n",
        "\n",
        "     It measures the reduction in uncertainty (entropy) about the class labels after splitting the dataset using a feature.\n",
        "\n",
        "    Interpretation\n",
        "\n",
        "     If a feature perfectly separates the classes → Entropy after split = 0 → IG is maximum.\n",
        "\n",
        "     If a feature does not help separate classes → IG = 0 (no reduction in uncertainty).\n",
        "\n",
        "     i.Guides splitting:\n",
        "\n",
        "   The decision tree chooses the feature with the highest IG because it creates the purest child nodes.\n",
        "\n",
        "   ii.Prevents random splits:\n",
        "\n",
        "   Without IG (or similar metrics like Gini), the tree might split on irrelevant features.\n",
        "\n",
        "     iii. Improves accuracy:\n",
        "\n",
        "     By always choosing splits that maximize information, the tree makes better predictions.\n",
        "\n",
        "     iv. Ensures interpretability:\n",
        "\n",
        "     Features chosen early (with high IG) are the most informative, making the model easier to explain.\n",
        "\n",
        "\n",
        "5. What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "\n",
        "     -> Common Real-World Applications of Decision Trees\n",
        "\n",
        "     Healthcare & Medical Diagnosis\n",
        "\n",
        "     Predicting whether a patient has a certain disease based on symptoms, age, lifestyle factors.\n",
        "\n",
        "     Example: Classify patients as “high risk” vs. “low risk” for heart disease.\n",
        "\n",
        "     Finance & Banking\n",
        "\n",
        "    Credit risk assessment: Approve or reject loan applications.\n",
        "\n",
        "   Fraud detection: Classify transactions as fraudulent or legitimate.\n",
        "\n",
        "   Marketing & Customer Analytics\n",
        "\n",
        "  Customer segmentation (e.g., “likely to buy” vs. “not likely”).\n",
        "\n",
        "   Churn prediction (whether a customer will leave a service).\n",
        "\n",
        "   Operations & Supply Chain\n",
        "\n",
        "Demand forecasting (predicting product demand).\n",
        "\n",
        "Inventory decision-making.\n",
        "\n",
        "Human Resources\n",
        "\n",
        "Employee attrition prediction (will an employee stay or quit?).\n",
        "\n",
        "Resume screening and candidate selection.\n",
        "\n",
        "Retail & E-commerce\n",
        "\n",
        "Recommendation systems (products based on user behavior).\n",
        "\n",
        "Pricing strategy optimization.\n",
        "\n",
        "Manufacturing & Engineering\n",
        "\n",
        "Quality control (defective vs. non-defective products).\n",
        "\n",
        "Fault detection in machines.\n",
        "\n",
        "  Main Advantages of Decision Trees\n",
        "\n",
        "Easy to Understand & Interpret\n",
        "\n",
        "Looks like a flowchart → managers and non-technical users can interpret it.\n",
        "\n",
        "Handles Both Numeric & Categorical Data\n",
        "\n",
        "Works well with mixed types of features.\n",
        "\n",
        "Non-linear Relationships\n",
        "\n",
        "Can model complex decision boundaries without requiring linear assumptions.\n",
        "\n",
        "Requires Little Data Preparation\n",
        "\n",
        "No need for feature scaling or normalization.\n",
        "\n",
        "Fast for Prediction\n",
        "\n",
        "Once built, classifying a new case is quick (just follow the path).\n",
        "\n",
        " Main Limitations of Decision Trees\n",
        "\n",
        "Overfitting\n",
        "\n",
        "Trees can grow too deep and memorize training data.\n",
        "\n",
        "Controlled with pruning or ensemble methods (Random Forests, Gradient Boosted Trees).\n",
        "\n",
        "Instability\n",
        "\n",
        "Small changes in data → very different tree.\n",
        "\n",
        "Bias Toward Features with Many Levels\n",
        "\n",
        "Features with more categories may appear artificially “better” (higher information gain).\n",
        "\n",
        "Not Always the Most Accurate\n",
        "\n",
        "Alone, they’re often outperformed by ensemble methods (Random Forests, XGBoost).\n",
        "\n",
        "Greedy Nature\n",
        "\n",
        "Splits are chosen locally at each node; may not yield the globally optimal tree.\n",
        "\n",
        "\n",
        "6. Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "\n",
        "● Print the model’s accuracy and feature importances ."
      ],
      "metadata": {
        "id": "e5IMHy6NT_Ba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JEro9hAdTrUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b70a3fb-61fe-402f-a6c6-433ecf708ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n",
            "\n",
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0191\n",
            "petal length (cm): 0.8933\n",
            "petal width (cm): 0.0876\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 2. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train a Decision Tree Classifier using Gini criterion\n",
        "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 4. Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# 5. Print the model’s accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "# 6. Print feature importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature_name, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "\n",
        "a fully-grown tree."
      ],
      "metadata": {
        "id": "YsVvMGYmYHEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 2. Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train a Decision Tree with max_depth=3\n",
        "shallow_tree = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, random_state=42)\n",
        "shallow_tree.fit(X_train, y_train)\n",
        "\n",
        "# 4. Train a fully-grown Decision Tree (no depth limit)\n",
        "full_tree = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "full_tree.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predictions\n",
        "y_pred_shallow = shallow_tree.predict(X_test)\n",
        "y_pred_full = full_tree.predict(X_test)\n",
        "\n",
        "# 6. Accuracy comparison\n",
        "acc_shallow = accuracy_score(y_test, y_pred_shallow)\n",
        "acc_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "print(\"Decision Tree (max_depth=3) Accuracy:\", acc_shallow)\n",
        "print(\"Decision Tree (Fully-grown) Accuracy:\", acc_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tziQp1a7XGZy",
        "outputId": "2b462010-470e-499d-d812-e3dc9cb23d8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree (max_depth=3) Accuracy: 1.0\n",
            "Decision Tree (Fully-grown) Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Write a Python program to:\n",
        "\n",
        "● Load the California Housing dataset from sklearn\n",
        "\n",
        "● Train a Decision Tree Regressor\n",
        "\n",
        "● Print the Mean Squared Error (MSE) and feature importances ."
      ],
      "metadata": {
        "id": "lK6VRTGvZNDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1. Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# 2. Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train a Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predictions\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# 5. Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# 6. Print feature importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature_name, importance in zip(housing.feature_names, regressor.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBcDtXqsZIKa",
        "outputId": "748cfb51-7539-45d3-e9cd-a40d54a43ae0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.5280096503174904\n",
            "\n",
            "Feature Importances:\n",
            "MedInc: 0.5235\n",
            "HouseAge: 0.0521\n",
            "AveRooms: 0.0494\n",
            "AveBedrms: 0.0250\n",
            "Population: 0.0322\n",
            "AveOccup: 0.1390\n",
            "Latitude: 0.0900\n",
            "Longitude: 0.0888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "\n",
        "● Print the best parameters and the resulting model accuracy"
      ],
      "metadata": {
        "id": "B6KaY8J3aNH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 2. Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Define the Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# 4. Define the parameter grid for tuning\n",
        "param_grid = {\n",
        "    \"max_depth\": [2, 3, 4, 5, None],\n",
        "    \"min_samples_split\": [2, 3, 4, 5, 10]\n",
        "}\n",
        "\n",
        "# 5. Apply GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid,\n",
        "                           cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 6. Best parameters and accuracy\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Test Set Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqW0RSgaFwZ",
        "outputId": "66c782bc-23ab-4d3d-9562-ee33aa0fe06f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 10}\n",
            "Test Set Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "\n",
        "● Handle the missing values\n",
        "\n",
        "● Encode the categorical features\n",
        "\n",
        "● Train a Decision Tree model\n",
        "\n",
        "● Tune its hyperparameters\n",
        "\n",
        "● Evaluate its performance\n",
        "\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        "  \n",
        "   -> First things to do (quick data triage)\n",
        "\n",
        "  i.Inspect dataset size, column types, and target balance (class frequencies).\n",
        "\n",
        "  ii. check missingness pattern (MCAR / MAR / MNAR) and whether missingness correlates with the target.\n",
        "\n",
        "   iii. Check if data are time-ordered (EHR/time-series) — if yes, use time-aware splitting.\n",
        "\n",
        "   iv. Decide primary business metric early (recall/sensitivity vs precision vs ROC-AUC) — this drives imputation/thresholding/tuning.\n",
        "\n",
        "   I. Handling missing values\n",
        "\n",
        "  Explore missingness\n",
        "\n",
        "  Per-column % missing, pairwise missingness patterns, and whether missingness predicts the label.\n",
        "\n",
        "  Decide strategy by cause & column type\n",
        "\n",
        "  Drop rows/cols only if missingness is rare or a column is useless.\n",
        "\n",
        "  Numeric features\n",
        "\n",
        "  Simple: median (robust to outliers) or mean (if symmetric).\n",
        "\n",
        "  Advanced: KNNImputer or IterativeImputer (MICE) when values are correlated.\n",
        "\n",
        "  Categorical features\n",
        "\n",
        "  Replace with a new category \"MISSING\" or the mode.\n",
        "\n",
        "For high-cardinality, consider grouping rare levels to \"Other\" before imputation.\n",
        "\n",
        "Missingness as signal\n",
        "\n",
        "If missingness itself is informative (e.g., a test only ordered for sicker patients), create a binary missing indicator column.\n",
        "\n",
        "Avoid leakage\n",
        "\n",
        "Always fit imputers only on training data inside a pipeline (use SimpleImputer/IterativeImputer in an sklearn Pipeline or ColumnTransformer) so validation/test data are not used to compute imputation statistics.\n",
        "\n",
        "Temporal data\n",
        "\n",
        "For repeated measures, use forward/backfill or model-based imputation that respects time order.\n",
        "\n",
        "2) Encoding categorical features\n",
        "\n",
        "Decision trees don’t require scaled inputs, but they do require numeric encoding of categories for sklearn.\n",
        "\n",
        "Strategies:\n",
        "\n",
        "One-Hot Encoding (safe, interpretable): good for low-to-moderate cardinality. Use OneHotEncoder(handle_unknown='ignore') in a pipeline.\n",
        "\n",
        "Ordinal / Label Encoding: okay only for truly ordinal features. For nominal features, label encoding can accidentally inject order; avoid unless tree library supports categorical split natively.\n",
        "\n",
        "Target / Leave-One-Out Encoding: powerful for high-cardinality (e.g., ICD codes). Important: avoid leakage — compute encodings inside cross-validation folds or use smoothing and out-of-fold target stats (use CategoryEncoders or implement fold-based encoding).\n",
        "\n",
        "Frequency / Count encoding: simple and often effective for high-cardinality.\n",
        "\n",
        "Implement using ColumnTransformer so numeric and categorical pipelines are separate.\n",
        "\n",
        "3) Train a Decision Tree (practical recipe)\n",
        "\n",
        "Basic pipeline (sketch) — keeps preprocessing + model together, avoids leakage :"
      ],
      "metadata": {
        "id": "9QlZXKobb-wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define your numeric and categorical column names here\n",
        "numeric_cols = ['placeholder_numeric_col_1', 'placeholder_numeric_col_2'] # Replace with your actual numeric column names\n",
        "categorical_cols = ['placeholder_categorical_col_1', 'placeholder_categorical_col_2'] # Replace with your actual categorical column names\n",
        "\n",
        "# Define your transformers for numeric and categorical features\n",
        "# Example: Impute missing numeric values with the median\n",
        "numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
        "\n",
        "# Example: Impute missing categorical values with a constant and then one-hot encode\n",
        "cat_transformer = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='MISSING')),\n",
        "                            ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_cols),\n",
        "    ('cat', cat_transformer, categorical_cols),\n",
        "])\n",
        "\n",
        "clf_pipeline = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "# You would then fit this pipeline to your data:\n",
        "# clf_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nWJBB2vge0QS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning\n",
        "\n",
        "Use GridSearchCV or RandomizedSearchCV wrapped around the full pipeline (preprocessing + model) to avoid leakage.\n",
        "\n",
        "Example parameter grid (tweak ranges as needed):"
      ],
      "metadata": {
        "id": "92eSLsGCg6_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'clf__max_depth': [3, 5, 7, 10, None],\n",
        "    'clf__min_samples_split': [2, 5, 10, 20],\n",
        "    'clf__min_samples_leaf': [1, 2, 5, 10],\n",
        "    'clf__criterion': ['gini','entropy'],\n",
        "    'clf__ccp_alpha': [0.0, 0.001, 0.01]  # pruning\n",
        "}\n"
      ],
      "metadata": {
        "id": "OwQd5Wasgrvy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation & interpretability\n",
        "\n",
        "Metrics\n",
        "\n",
        "Confusion matrix (TP, FP, FN, TN).\n",
        "\n",
        "Recall (sensitivity) — critical if missing a disease is costly.\n",
        "\n",
        "Precision — important if follow-up tests are expensive/harmful.\n",
        "\n",
        "F1 — balanced precision/recall.\n",
        "\n",
        "ROC AUC and PR AUC (PR AUC is better for imbalanced problems).\n",
        "\n",
        "Calibration (do predicted probabilities match true probabilities?) — use calibration plots and CalibratedClassifierCV if needed.\n",
        "\n",
        "Threshold tuning\n",
        "\n",
        "Tune decision threshold using validation data to optimize expected business cost (e.g., tradeoff FN vs FP).\n",
        "\n",
        "Interpretability\n",
        "\n",
        "feature_importances_ (quick but can be misleading).\n",
        "\n",
        "Permutation importance (more reliable).\n",
        "\n",
        "SHAP or LIME for per-prediction explanations — very useful in clinical settings to show why a patient was flagged.\n",
        "\n",
        "Robustness checks\n",
        "\n",
        "Subgroup performance (age, sex, ethnicity) — check fairness and disparate impact.\n",
        "\n",
        "Sensitivity to missingness and imputation choices.\n",
        "\n",
        "Test on an external holdout or prospective cohort if possible.\n",
        "\n",
        "Statistical confidence\n",
        "\n",
        "Report confidence intervals for metrics (bootstrapping or CV-based intervals).\n",
        "\n",
        "6) Deployment, monitoring & governance\n",
        "\n",
        "Human-in-the-loop: deliver predictions as decision support, not autonomous decisions — clinicians should review flagged cases.\n",
        "\n",
        "Pilot / prospective validation: test model in real workflow before full rollout (A/B test or prospective cohort) to measure clinical impact and false alarm rates.\n",
        "\n",
        "Monitoring: track model performance over time (drift detection), track input feature distributions and label distribution shifts, trigger retraining when performance drops.\n",
        "\n",
        "Logging & auditability: store predictions, inputs, clinician overrides, and outcomes for post-hoc analysis and regulatory compliance.\n",
        "\n",
        "Privacy & compliance: ensure EHR/HIPAA-compliant storage and processing; follow local regulations.\n",
        "\n",
        "Explainability & acceptance: produce short human-friendly explanations with each prediction; involve clinicians in threshold setting.\n",
        "\n",
        "7) Business value (what this model can deliver)\n",
        "\n",
        "Early detection / triage: prioritize patients for further testing or early intervention → could reduce morbidity and downstream costs.\n",
        "\n",
        "Resource optimization: route scarce diagnostic tests and specialist time to the most likely-positive patients.\n",
        "\n",
        "Cost savings: reduce unnecessary tests or admissions if the model reduces false positives when properly tuned.\n",
        "\n",
        "Operational efficiency: faster screening, reduced clinician workload on low-risk patients.\n",
        "\n",
        "Measurable outcomes: improved time-to-diagnosis, reduced hospitalization rates, improved patient outcomes — measurable via an impact study or pilot.\n",
        "\n",
        "Risks to manage: false negatives (missed disease) can be harmful; false positives cause anxiety and extra costs — choose thresholds and workflows to balance risk according to business/clinical priorities.\n",
        "\n",
        "Quick practical checklist\n",
        "\n",
        "EDA: missingness, distributions, class balance.\n",
        "\n",
        "Build preprocessing ColumnTransformer (impute numeric, impute & encode categorical).\n",
        "\n",
        "Pipeline → DecisionTreeClassifier(class_weight='balanced', random_state=42).\n",
        "\n",
        "Tune parameters with GridSearchCV/RandomizedSearchCV and stratified CV; pick metric that matches clinical objective.\n",
        "\n",
        "Evaluate with confusion matrix, ROC/PR AUC, calibration, and subgroup checks.\n",
        "\n",
        "Explain results (feature importances, SHAP), pilot in clinic, then deploy with monitoring and retraining plan."
      ],
      "metadata": {
        "id": "5uKVGhcbhElZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OMCr3QYNhCqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}